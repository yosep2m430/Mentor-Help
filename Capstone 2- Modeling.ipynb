{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "628f962b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.preprocessing import scale\n",
    "from sklearn.model_selection import train_test_split, cross_validate, GridSearchCV, learning_curve, cross_val_score, RandomizedSearchCV\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "\n",
    "from sklearn.dummy import DummyRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor, RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error, accuracy_score, classification_report\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from bayes_opt import BayesianOptimization\n",
    "import lightgbm as lgb\n",
    "\n",
    "from sklearn.feature_selection import mutual_info_regression, SelectKBest, f_regression\n",
    "from sklearn.utils import resample\n",
    "import xgboost as xgb\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "random_state=42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3268495e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df= pd.read_csv('/Users/josephlim/Desktop/Data Science/Capstone Projects/Capstone project- Spotify/Data/Cleaned Data/spotify_data_preprocessed.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b73c1d49",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>popularity</th>\n",
       "      <th>duration_ms</th>\n",
       "      <th>danceability</th>\n",
       "      <th>loudness</th>\n",
       "      <th>speechiness</th>\n",
       "      <th>acousticness</th>\n",
       "      <th>instrumentalness</th>\n",
       "      <th>liveness</th>\n",
       "      <th>valence</th>\n",
       "      <th>tempo</th>\n",
       "      <th>time_signature</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.14</td>\n",
       "      <td>266773</td>\n",
       "      <td>0.429</td>\n",
       "      <td>-7.227</td>\n",
       "      <td>0.0281</td>\n",
       "      <td>0.00239</td>\n",
       "      <td>0.000121</td>\n",
       "      <td>0.2340</td>\n",
       "      <td>0.285</td>\n",
       "      <td>173.372</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.33</td>\n",
       "      <td>201960</td>\n",
       "      <td>0.659</td>\n",
       "      <td>-5.850</td>\n",
       "      <td>0.0437</td>\n",
       "      <td>0.00450</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.3350</td>\n",
       "      <td>0.798</td>\n",
       "      <td>106.965</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.16</td>\n",
       "      <td>216880</td>\n",
       "      <td>0.556</td>\n",
       "      <td>-5.870</td>\n",
       "      <td>0.0584</td>\n",
       "      <td>0.00958</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.2090</td>\n",
       "      <td>0.400</td>\n",
       "      <td>105.143</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.16</td>\n",
       "      <td>284200</td>\n",
       "      <td>0.949</td>\n",
       "      <td>-4.244</td>\n",
       "      <td>0.0572</td>\n",
       "      <td>0.03020</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0454</td>\n",
       "      <td>0.760</td>\n",
       "      <td>104.504</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.63</td>\n",
       "      <td>201960</td>\n",
       "      <td>0.659</td>\n",
       "      <td>-5.850</td>\n",
       "      <td>0.0437</td>\n",
       "      <td>0.00450</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.3350</td>\n",
       "      <td>0.798</td>\n",
       "      <td>106.965</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   popularity  duration_ms  danceability  loudness  speechiness  acousticness  \\\n",
       "0        0.14       266773         0.429    -7.227       0.0281       0.00239   \n",
       "1        0.33       201960         0.659    -5.850       0.0437       0.00450   \n",
       "2        0.16       216880         0.556    -5.870       0.0584       0.00958   \n",
       "3        0.16       284200         0.949    -4.244       0.0572       0.03020   \n",
       "4        0.63       201960         0.659    -5.850       0.0437       0.00450   \n",
       "\n",
       "   instrumentalness  liveness  valence    tempo  time_signature  \n",
       "0          0.000121    0.2340    0.285  173.372               4  \n",
       "1          0.000002    0.3350    0.798  106.965               4  \n",
       "2          0.000000    0.2090    0.400  105.143               4  \n",
       "3          0.000000    0.0454    0.760  104.504               4  \n",
       "4          0.000002    0.3350    0.798  106.965               4  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "333a0bd8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 92194 entries, 0 to 92193\n",
      "Data columns (total 11 columns):\n",
      " #   Column            Non-Null Count  Dtype  \n",
      "---  ------            --------------  -----  \n",
      " 0   popularity        92194 non-null  float64\n",
      " 1   duration_ms       92194 non-null  int64  \n",
      " 2   danceability      92194 non-null  float64\n",
      " 3   loudness          92194 non-null  float64\n",
      " 4   speechiness       92194 non-null  float64\n",
      " 5   acousticness      92194 non-null  float64\n",
      " 6   instrumentalness  92194 non-null  float64\n",
      " 7   liveness          92194 non-null  float64\n",
      " 8   valence           92194 non-null  float64\n",
      " 9   tempo             92194 non-null  float64\n",
      " 10  time_signature    92194 non-null  int64  \n",
      "dtypes: float64(9), int64(2)\n",
      "memory usage: 7.7 MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "56de8bee",
   "metadata": {},
   "outputs": [],
   "source": [
    "X= df.drop('popularity', axis=1)\n",
    "y= df['popularity']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8744e60",
   "metadata": {},
   "source": [
    "Let's split the data into training and testing sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "49b547df",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test= train_test_split(X, y,test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3c7f8d20",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>popularity</th>\n",
       "      <th>duration_ms</th>\n",
       "      <th>danceability</th>\n",
       "      <th>loudness</th>\n",
       "      <th>speechiness</th>\n",
       "      <th>acousticness</th>\n",
       "      <th>instrumentalness</th>\n",
       "      <th>liveness</th>\n",
       "      <th>valence</th>\n",
       "      <th>tempo</th>\n",
       "      <th>time_signature</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>92194.000000</td>\n",
       "      <td>9.219400e+04</td>\n",
       "      <td>92194.000000</td>\n",
       "      <td>92194.000000</td>\n",
       "      <td>92194.00000</td>\n",
       "      <td>92194.000000</td>\n",
       "      <td>92194.000000</td>\n",
       "      <td>92194.000000</td>\n",
       "      <td>92194.000000</td>\n",
       "      <td>92194.000000</td>\n",
       "      <td>92194.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.620856</td>\n",
       "      <td>2.385335e+05</td>\n",
       "      <td>0.600292</td>\n",
       "      <td>-7.563552</td>\n",
       "      <td>0.08614</td>\n",
       "      <td>0.306901</td>\n",
       "      <td>0.063995</td>\n",
       "      <td>0.207626</td>\n",
       "      <td>0.545761</td>\n",
       "      <td>121.392948</td>\n",
       "      <td>3.925559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.162090</td>\n",
       "      <td>1.132078e+05</td>\n",
       "      <td>0.159702</td>\n",
       "      <td>3.763095</td>\n",
       "      <td>0.11218</td>\n",
       "      <td>0.295936</td>\n",
       "      <td>0.205188</td>\n",
       "      <td>0.184344</td>\n",
       "      <td>0.252382</td>\n",
       "      <td>29.337843</td>\n",
       "      <td>0.364847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.060000</td>\n",
       "      <td>6.360000e+03</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-60.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.510000</td>\n",
       "      <td>1.949470e+05</td>\n",
       "      <td>0.498000</td>\n",
       "      <td>-9.042000</td>\n",
       "      <td>0.03320</td>\n",
       "      <td>0.040300</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.096000</td>\n",
       "      <td>0.343000</td>\n",
       "      <td>97.951500</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.610000</td>\n",
       "      <td>2.288025e+05</td>\n",
       "      <td>0.611000</td>\n",
       "      <td>-6.816000</td>\n",
       "      <td>0.04480</td>\n",
       "      <td>0.208000</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.132000</td>\n",
       "      <td>0.549000</td>\n",
       "      <td>120.379000</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.720000</td>\n",
       "      <td>2.687652e+05</td>\n",
       "      <td>0.716000</td>\n",
       "      <td>-5.143000</td>\n",
       "      <td>0.08200</td>\n",
       "      <td>0.530000</td>\n",
       "      <td>0.000607</td>\n",
       "      <td>0.266000</td>\n",
       "      <td>0.758000</td>\n",
       "      <td>139.847750</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.995083e+06</td>\n",
       "      <td>0.991000</td>\n",
       "      <td>2.854000</td>\n",
       "      <td>0.96200</td>\n",
       "      <td>0.996000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>220.230000</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         popularity   duration_ms  danceability      loudness  speechiness  \\\n",
       "count  92194.000000  9.219400e+04  92194.000000  92194.000000  92194.00000   \n",
       "mean       0.620856  2.385335e+05      0.600292     -7.563552      0.08614   \n",
       "std        0.162090  1.132078e+05      0.159702      3.763095      0.11218   \n",
       "min        0.060000  6.360000e+03      0.000000    -60.000000      0.00000   \n",
       "25%        0.510000  1.949470e+05      0.498000     -9.042000      0.03320   \n",
       "50%        0.610000  2.288025e+05      0.611000     -6.816000      0.04480   \n",
       "75%        0.720000  2.687652e+05      0.716000     -5.143000      0.08200   \n",
       "max        1.000000  4.995083e+06      0.991000      2.854000      0.96200   \n",
       "\n",
       "       acousticness  instrumentalness      liveness       valence  \\\n",
       "count  92194.000000      92194.000000  92194.000000  92194.000000   \n",
       "mean       0.306901          0.063995      0.207626      0.545761   \n",
       "std        0.295936          0.205188      0.184344      0.252382   \n",
       "min        0.000000          0.000000      0.000000      0.000000   \n",
       "25%        0.040300          0.000000      0.096000      0.343000   \n",
       "50%        0.208000          0.000003      0.132000      0.549000   \n",
       "75%        0.530000          0.000607      0.266000      0.758000   \n",
       "max        0.996000          1.000000      1.000000      1.000000   \n",
       "\n",
       "              tempo  time_signature  \n",
       "count  92194.000000    92194.000000  \n",
       "mean     121.392948        3.925559  \n",
       "std       29.337843        0.364847  \n",
       "min        0.000000        0.000000  \n",
       "25%       97.951500        4.000000  \n",
       "50%      120.379000        4.000000  \n",
       "75%      139.847750        4.000000  \n",
       "max      220.230000        5.000000  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53156644",
   "metadata": {},
   "source": [
    "### Dummy Regressor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18145144",
   "metadata": {},
   "source": [
    "Let's explore different models we can predict popularity by. A good starting point would be to see how good the mean would be as a predictor. DummyRegressor can do just that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e1ba1510",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6206697141086231"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_mean= y_train.mean()\n",
    "train_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0fbe60a0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1.4600769697281635e-05"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dumb_reg= DummyRegressor(strategy='mean')\n",
    "\n",
    "dumb_reg.fit(X_train, y_train)\n",
    "dumb_reg.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1b8247d",
   "metadata": {},
   "source": [
    "It comes pretty close for now, but how good is this? We'll see how closely this explains the actual values. There are many metrics we can use to do this. We will try different metrics to choose which one works best for our specific scenario."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48199636",
   "metadata": {},
   "source": [
    "## Metrics\n",
    "\n",
    "**1. Coefficient of determination ($R^{2}$):**\n",
    "<br> We will make predictions by creating length of size of training set with the single value of the mean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e6827d38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.62066971, 0.62066971, 0.62066971, 0.62066971, 0.62066971])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_tr_pred_ = train_mean* np.ones(len(y_train))\n",
    "y_tr_pred_[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b7acd28f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.62066971, 0.62066971, 0.62066971, 0.62066971, 0.62066971])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_tr_pred= dumb_reg.predict(X_train)\n",
    "y_tr_pred[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1e97145",
   "metadata": {},
   "source": [
    "They produce exactly same results. Let's find out ($R^{2}$) score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "36afd2f3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2_score(y_train, y_tr_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec9a3d5e",
   "metadata": {},
   "source": [
    "We got $R^{2}$ score of 0 on our training set when we used mean as a predictor. $R^{2}$ explains predictions in terms of the amount of variance. Low $R^{2}$ score suggests small amount of variances explainedn. Let's try this on our test set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6dd38988",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1.4600769697281635e-05"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_te_pred= train_mean*np.ones(len(y_test))\n",
    "r2_score(y_test, y_te_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c771dfb",
   "metadata": {},
   "source": [
    "This negative number was expected, because most models perform worse on test sets than on training sets."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f82f78f5",
   "metadata": {},
   "source": [
    "**2.Mean Absolute Error (MAE)**\n",
    "<br>\n",
    "MAE tells us how much we expect to be off by if we guessed based on the average of known values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "112a9959",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.1278059219662443, 0.12801506385334058)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_absolute_error(y_train, y_tr_pred), mean_absolute_error(y_test, y_te_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9104ce9c",
   "metadata": {},
   "source": [
    "MAE on testing set is very slightly worse than on training data, but they are very similar."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd85646f",
   "metadata": {},
   "source": [
    "**3.Mean Squared Error (MSE)**\n",
    "<br>Mean squared error is the average of square of errors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b989737b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.026265295652843034, 0.026290308453708538)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(y_train, y_tr_pred), mean_squared_error(y_test, y_te_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e48cec88",
   "metadata": {},
   "source": [
    "While it was pretty obvious from $R^{2}$ score that a simple average would not be the best model, it was worth double (or triple) checking it using different metrics. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1f734c8",
   "metadata": {},
   "source": [
    "## Initial Models:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "564edfe7",
   "metadata": {},
   "source": [
    "Let's build pipelines to simplify processes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3c7d2913",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = make_pipeline(\n",
    "    StandardScaler(),\n",
    "    LinearRegression()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "174f8607",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sklearn.pipeline.Pipeline"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(pipe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "53af0707",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(True, True)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hasattr(pipe, 'fit'), hasattr(pipe, 'predict')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc1b9a16",
   "metadata": {},
   "source": [
    "Let's try fitting, making predictions, and evaluating performance using this pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0c056df5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('standardscaler', StandardScaler()),\n",
       "                ('linearregression', LinearRegression())])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "38192911",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_tr_pred= pipe.predict(X_train)\n",
    "y_te_pred= pipe.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c80da551",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.05735959711767247, 0.05996889136075756)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2_score(y_train, y_tr_pred), r2_score(y_test, y_te_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e0af42b",
   "metadata": {},
   "source": [
    "Given the number of features, it is possible that I am overfitting. As such, I will limit number of features that get used based on f_regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c458aa32",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = make_pipeline(\n",
    "    StandardScaler(),\n",
    "    SelectKBest(f_regression),\n",
    "    LinearRegression()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9886248f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('standardscaler', StandardScaler()),\n",
       "                ('selectkbest',\n",
       "                 SelectKBest(score_func=<function f_regression at 0x7f83c3492790>)),\n",
       "                ('linearregression', LinearRegression())])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8de99d56",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_tr_pred = pipe.predict(X_train)\n",
    "y_te_pred = pipe.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1e41fd39",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.05735959711767247, 0.05996889136075756)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2_score(y_train, y_tr_pred), r2_score(y_test, y_te_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0aef2356",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.12512771154799862, 0.12530144115509462)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_absolute_error(y_train, y_tr_pred), mean_absolute_error(y_test, y_te_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a37562cb",
   "metadata": {},
   "source": [
    "We see that our model performance got much worse than when we didn't limit features. This was an expected result of limiting feature numbers. Let's try to include more."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0057674e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe10 = make_pipeline(\n",
    "    StandardScaler(),\n",
    "    SelectKBest(f_regression, k=10),\n",
    "    LinearRegression()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c8df7f41",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_tr_pred = pipe.predict(X_train)\n",
    "y_te_pred = pipe.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "59101fe2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.05735959711767247, 0.05996889136075756)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2_score(y_train, y_tr_pred), r2_score(y_test, y_te_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f90de14b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.12512771154799862, 0.12530144115509462)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_absolute_error(y_train, y_tr_pred), mean_absolute_error(y_test, y_te_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c86fe36",
   "metadata": {},
   "source": [
    "It didn't make too much of a difference. Let's try to use cross-validation to assess model performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e7b1a73a",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_results= cross_validate(pipe10, X_train, y_train, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8c9958c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.06189826, 0.05326071, 0.05647042, 0.05476803, 0.05775996])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_scores= cv_results['test_score']\n",
    "cv_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e01859c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.05683147698481341, 0.0029554351736718943)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(cv_scores), np.std(cv_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bb5a0ac",
   "metadata": {},
   "source": [
    "We can estimate the variability, or uncertainty of model performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b0fbe91a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.05, 0.06])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.round((np.mean(cv_scores) - 2 * np.std(cv_scores), np.mean(cv_scores) + 2 * np.std(cv_scores)), 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f502d61",
   "metadata": {},
   "source": [
    "## Linear Regression Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eae6c7cd",
   "metadata": {},
   "source": [
    "### GridSearchCV - Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea3bdb80",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe.get_params().keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68534b63",
   "metadata": {},
   "outputs": [],
   "source": [
    "k = [k+1 for k in range(len(X_train.columns))]\n",
    "grid_params = {'selectkbest__k': k}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c3dc902",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_grid_cv = GridSearchCV(pipe, param_grid=grid_params, cv=5, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a8a0d48",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_grid_cv.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "392d4275",
   "metadata": {},
   "outputs": [],
   "source": [
    "score_mean = lr_grid_cv.cv_results_['mean_test_score']\n",
    "score_std = lr_grid_cv.cv_results_['std_test_score']\n",
    "cv_k = [k for k in lr_grid_cv.cv_results_['param_selectkbest__k']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e83fa511",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_grid_cv.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d467a2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_k = lr_grid_cv.best_params_['selectkbest__k']\n",
    "plt.subplots(figsize=(10, 5))\n",
    "plt.errorbar(cv_k, score_mean, yerr=score_std)\n",
    "plt.axvline(x=best_k, c='r', ls='--', alpha=.5)\n",
    "plt.xlabel('k')\n",
    "plt.ylabel('CV score (r-squared)')\n",
    "plt.title('Pipeline mean CV score (error bars +/- 1sd)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5def58cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected = lr_grid_cv.best_estimator_.named_steps.selectkbest.get_support()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8d4c967",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "coefs= lr_grid_cv.best_estimator_.named_steps.linearregression.coef_\n",
    "features= X_train.columns[selected]\n",
    "pd.Series(coefs, index= features).sort_values(ascending= False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bdf1ceb",
   "metadata": {},
   "source": [
    "We see that the most positive feature were instrumentalness. This differs from our EDA, which showed preference to non-instrumentalness. Let's try a different model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fd3c1ce",
   "metadata": {},
   "source": [
    "## Random Forest Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2329807",
   "metadata": {},
   "outputs": [],
   "source": [
    "RF= RandomForestRegressor(random_state= 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70599fa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_default_cv_results= cross_validate(RF, X_train, y_train, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6a99d8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_cv_scores= rf_default_cv_results['test_score']\n",
    "rf_cv_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c07ea8b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "np.mean(rf_cv_scores), np.std(rf_cv_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b01477f0",
   "metadata": {},
   "source": [
    "Random Forest Regression model looks much more promising. Let's see what hyperparameter tuning can do for this model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e2f80e7",
   "metadata": {},
   "source": [
    "#### Random Forest Model- Bayesian Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f6090a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_results.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74c515e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1528da22",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16250d06",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_model(n_estimators, min_samples_split, max_depth, max_features):\n",
    "    num_leaves= round(num_leaves)\n",
    "    max_depth= round(max_depth)\n",
    "    min_child_samples= round(min_child_samples)\n",
    "    min_data_in_leaf= round(min_data_in_leaf)\n",
    "    \n",
    "    regressor= RandomForestRegressor(num_leaves= num_leaves, \n",
    "                                 max_depth=max_depth,\n",
    "                                 min_child_samples= min_child_samples, \n",
    "                                 random_state=random_state)\n",
    "\n",
    "    return np.mean(cross_validate(regressor, X_train, y_train, scoring='r2', cv=5, return_train_score=True)['test_score'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d881cd9d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "rf_BO = BayesianOptimization(fit_model,{\n",
    "        \"n_estimators\":(300, 2000), \n",
    "        \"min_samples_split\":(20,100), \n",
    "        \"max_depth\":(3,7), \n",
    "        \"max_features\":(5,13) \n",
    "    })\n",
    "\n",
    "rf_BO.maximize(n_iter=10, init_points=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcfb807a",
   "metadata": {},
   "source": [
    "### Gradient Boosting Model\n",
    "The performance of Random Forest Model wasn't as good as I hoped. Let's try a gradient boosting model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf0afd46",
   "metadata": {},
   "source": [
    "#### Gradient Boosting Model- Bayesian Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "bf29e2fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lgb_eval(num_leaves, max_depth, min_child_samples, min_data_in_leaf):\n",
    "    num_leaves= round(num_leaves)\n",
    "    max_depth= round(max_depth)\n",
    "    min_child_samples= round(min_child_samples)\n",
    "    min_data_in_leaf= round(min_data_in_leaf)\n",
    "    \n",
    "    regressor= lgb.LGBMRegressor(num_leaves= num_leaves, \n",
    "                                 max_depth=max_depth,\n",
    "                                 min_child_samples= min_child_samples, \n",
    "                                 random_state=42)\n",
    "    \n",
    "    return np.mean(cross_validate(regressor, X_train, y_train, scoring='r2', cv=5, error_score= 'raise')['test_score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "8bb2d572",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|   iter    |  target   | max_depth | min_ch... | min_da... | num_le... |\n",
      "-------------------------------------------------------------------------\n",
      "| \u001b[0m1        \u001b[0m | \u001b[0m0.1199   \u001b[0m | \u001b[0m22.21    \u001b[0m | \u001b[0m2.954e+03\u001b[0m | \u001b[0m885.3    \u001b[0m | \u001b[0m3.693e+03\u001b[0m |\n",
      "| \u001b[95m2        \u001b[0m | \u001b[95m0.1462   \u001b[0m | \u001b[95m46.89    \u001b[0m | \u001b[95m297.6    \u001b[0m | \u001b[95m827.5    \u001b[0m | \u001b[95m596.8    \u001b[0m |\n",
      "| \u001b[0m3        \u001b[0m | \u001b[0m0.09064  \u001b[0m | \u001b[0m8.214    \u001b[0m | \u001b[0m8.122e+03\u001b[0m | \u001b[0m572.3    \u001b[0m | \u001b[0m2.456e+03\u001b[0m |\n",
      "| \u001b[0m4        \u001b[0m | \u001b[0m0.1238   \u001b[0m | \u001b[0m14.84    \u001b[0m | \u001b[0m2.496e+03\u001b[0m | \u001b[0m1.961e+03\u001b[0m | \u001b[0m45.2     \u001b[0m |\n",
      "| \u001b[0m5        \u001b[0m | \u001b[0m0.143    \u001b[0m | \u001b[0m58.84    \u001b[0m | \u001b[0m763.7    \u001b[0m | \u001b[0m1.149e+03\u001b[0m | \u001b[0m1.698e+03\u001b[0m |\n",
      "| \u001b[0m6        \u001b[0m | \u001b[0m0.1339   \u001b[0m | \u001b[0m43.54    \u001b[0m | \u001b[0m53.57    \u001b[0m | \u001b[0m373.5    \u001b[0m | \u001b[0m3.718e+03\u001b[0m |\n",
      "| \u001b[0m7        \u001b[0m | \u001b[0m0.1368   \u001b[0m | \u001b[0m59.02    \u001b[0m | \u001b[0m74.75    \u001b[0m | \u001b[0m1.984e+03\u001b[0m | \u001b[0m1.082e+03\u001b[0m |\n",
      "| \u001b[0m8        \u001b[0m | \u001b[0m0.1419   \u001b[0m | \u001b[0m32.54    \u001b[0m | \u001b[0m72.63    \u001b[0m | \u001b[0m178.7    \u001b[0m | \u001b[0m1.063e+03\u001b[0m |\n",
      "| \u001b[0m9        \u001b[0m | \u001b[0m0.1331   \u001b[0m | \u001b[0m23.31    \u001b[0m | \u001b[0m1.597e+03\u001b[0m | \u001b[0m142.3    \u001b[0m | \u001b[0m96.56    \u001b[0m |\n",
      "| \u001b[0m10       \u001b[0m | \u001b[0m0.1124   \u001b[0m | \u001b[0m48.83    \u001b[0m | \u001b[0m4.139e+03\u001b[0m | \u001b[0m1.574e+03\u001b[0m | \u001b[0m1.946e+03\u001b[0m |\n",
      "| \u001b[0m11       \u001b[0m | \u001b[0m0.1286   \u001b[0m | \u001b[0m9.406    \u001b[0m | \u001b[0m1.953e+03\u001b[0m | \u001b[0m1.531e+03\u001b[0m | \u001b[0m1.105e+03\u001b[0m |\n",
      "| \u001b[0m12       \u001b[0m | \u001b[0m0.1399   \u001b[0m | \u001b[0m53.35    \u001b[0m | \u001b[0m95.87    \u001b[0m | \u001b[0m1.934e+03\u001b[0m | \u001b[0m3.853e+03\u001b[0m |\n",
      "=========================================================================\n"
     ]
    }
   ],
   "source": [
    "lgbBO = BayesianOptimization(lgb_eval, {'num_leaves': (25, 4000),\n",
    "                                                'max_depth': (5, 63),\n",
    "                                                'min_child_samples': (50, 10000),\n",
    "                                                'min_data_in_leaf': (100, 2000)\n",
    "                                                })\n",
    "\n",
    "\n",
    "lgbBO.maximize(n_iter=10, init_points=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "a32800c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'target': 0.14623287399928964, 'params': {'max_depth': 46.89209917857136, 'min_child_samples': 297.64712942008214, 'min_data_in_leaf': 827.5177278231067, 'num_leaves': 596.8281699655965}}\n"
     ]
    }
   ],
   "source": [
    "print(lgbBO.max)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3931f607",
   "metadata": {},
   "source": [
    "Our prediction actually worsened. For now, our best bet is Random Forest regression model. However, I'm still not too excited about our current model performance. Perhaps we should try our hands at classification models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fba15140",
   "metadata": {},
   "source": [
    "### Classifications\n",
    "We'll try to predict songs' popularities by categorizing popularities(into \"high\",\"mid\",\"low\"), and classifying songs into those categories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "d040236e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        (0.0591, 0.373]\n",
       "1        (0.0591, 0.373]\n",
       "2        (0.0591, 0.373]\n",
       "3        (0.0591, 0.373]\n",
       "4         (0.373, 0.687]\n",
       "              ...       \n",
       "92189    (0.0591, 0.373]\n",
       "92190    (0.0591, 0.373]\n",
       "92191     (0.373, 0.687]\n",
       "92192    (0.0591, 0.373]\n",
       "92193     (0.373, 0.687]\n",
       "Name: popularity, Length: 92194, dtype: category\n",
       "Categories (3, interval[float64, right]): [(0.0591, 0.373] < (0.373, 0.687] < (0.687, 1.0]]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.cut(df['popularity'], bins=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "2a2292f1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "labels=['low','medium', 'high']\n",
    "df['popularity']= pd.cut(df['popularity'], bins=3, labels=labels, right=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "acf5c5ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "medium    57662\n",
       "high      29518\n",
       "low        5014\n",
       "Name: popularity, dtype: int64"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.popularity.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c973abe7",
   "metadata": {},
   "source": [
    "The dataset is unbalanced. This is intuitive, because there aren't as many popular songs as there are non-popular songs (otherwise, there will be much more financial stability in music industry!). However,imbalance in dataset will tamper with the accuracy of our model. One way to counteract this is by upsampling songs with high popularity.  We will then perform K-Nearest Neighbor classification, because they are good at handling noisy data. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af4d7b34",
   "metadata": {},
   "source": [
    "#### Up-sampling songs with \"high\" and \"low\" popularity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "8aac5525",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_high= df[df.popularity=='high']\n",
    "df_mid= df[df.popularity=='medium']\n",
    "df_low= df[df.popularity=='low']\n",
    "\n",
    "df_low_upsampled= resample(df_low, replace=True, n_samples= 57662, random_state=42)\n",
    "df_high_upsampled= resample(df_high, replace=True, n_samples=57662, random_state=42)\n",
    "\n",
    "\n",
    "list_df_upsampled=[df_high_upsampled, df_mid, df_low_upsampled]\n",
    "df_upsampled= pd.concat(list_df_upsampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "a5b8254b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "low       57662\n",
       "medium    57662\n",
       "high      57662\n",
       "Name: popularity, dtype: int64"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_upsampled.popularity.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "ab0cdc37",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_up= df_upsampled.drop('popularity', axis=1)\n",
    "y_up= df_upsampled['popularity']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "3f8c2b97",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test= train_test_split(X_up, y_up, random_state= 42, test_size=0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c495f68c",
   "metadata": {},
   "source": [
    "#### Testing Different Classification Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "611d5b57",
   "metadata": {},
   "source": [
    "**KNN Classifier** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f9e4e84",
   "metadata": {},
   "outputs": [],
   "source": [
    "KNN= KNeighborsClassifier()\n",
    "\n",
    "KNN.fit(X_train, y_train)\n",
    "\n",
    "y_pred_classification= KNN.predict(X_test)\n",
    "print(accuracy_score(y_test, y_pred_classification))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c972b8b1",
   "metadata": {},
   "source": [
    "WOW! This is a huge improvement (though it probably is overfitting). Let's try Random Forest Classification."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d34a6267",
   "metadata": {},
   "source": [
    "**Random Forest Classifier**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a268c35",
   "metadata": {},
   "outputs": [],
   "source": [
    "RFC= RandomForestClassifier(random_state= random_state)\n",
    "\n",
    "RFC.fit(X_train, y_train)\n",
    "y_rfc_pred= RFC.predict(X_test)\n",
    "print(accuracy_score(y_test, y_rfc_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc246484",
   "metadata": {},
   "source": [
    "Clearly, Random Forest Classifier performs best for our case. Let's use this model. Before fully delving into this model though, let's check for feature importance to see which features are more relevant for our task."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c54d476",
   "metadata": {},
   "source": [
    "**Feature Importances**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f94eea4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "importances= pd.Series(data= RFC.feature_importances_, index=X_train.columns)\n",
    "importances_sorted= importances.sort_values()\n",
    "\n",
    "importances_sorted.plot(kind='barh', color='blue')\n",
    "plt.title('Feature Importances')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1227d920",
   "metadata": {},
   "source": [
    "We see that loudness plays and duration plays the biggest role in predicting popularity. We then see that energy, valence, speechiness, acousticness, danceability, tempo, and liveness, in that order, influence our predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c57c2ef",
   "metadata": {},
   "source": [
    "#### Random Forest Classification- Bayesian Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "c16bbe1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_model(n_estimators, min_samples_split, max_depth, max_leaf_nodes):\n",
    "    n_estimators= round(n_estimators)\n",
    "    min_samples_split= round(min_samples_split) \n",
    "    max_depth= round(max_depth)\n",
    "    max_leaf_nodes= round(max_leaf_nodes)\n",
    "   \n",
    "    regressor= RandomForestClassifier(n_estimators= n_estimators, \n",
    "                                 min_samples_split= min_samples_split,\n",
    "                                 max_depth=max_depth,\n",
    "                                 random_state=random_state)\n",
    "\n",
    "    return np.mean(cross_validate(regressor, X_train, y_train, scoring='accuracy', error_score= 'raise', cv=5)['test_score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "244effcf",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|   iter    |  target   | max_depth | max_le... | min_sa... | n_esti... |\n",
      "-------------------------------------------------------------------------\n",
      "| \u001b[0m1        \u001b[0m | \u001b[0m0.4526   \u001b[0m | \u001b[0m2.822    \u001b[0m | \u001b[0m9.692    \u001b[0m | \u001b[0m99.47    \u001b[0m | \u001b[0m1.553e+03\u001b[0m |\n"
     ]
    }
   ],
   "source": [
    "rf_BO = BayesianOptimization(fit_model,{\n",
    "        'n_estimators': (5,2000),\n",
    "        'min_samples_split':(1,100), \n",
    "        'max_depth': (1,10),\n",
    "        'max_leaf_nodes': (2,10)\n",
    "    })\n",
    "\n",
    "rf_BO.maximize(n_iter=10, init_points=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0800dda9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(rf_BO.max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbd19fe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "Maybe try RandomizedSearchCV : https://www.geeksforgeeks.org/random-forest-hyperparameter-tuning-in-python/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "53be2f0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        high       0.83      0.86      0.84     16613\n",
      "         low       1.00      0.98      0.99     17795\n",
      "      medium       0.85      0.83      0.84     17488\n",
      "\n",
      "    accuracy                           0.89     51896\n",
      "   macro avg       0.89      0.89      0.89     51896\n",
      "weighted avg       0.89      0.89      0.89     51896\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = RandomForestClassifier()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "print(classification_report(y_pred, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "43f84763",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'n_estimators': [25, 50, 100, 150, 1000, 2000],\n",
    "    'max_features': ['sqrt', 'log2', None],\n",
    "    'max_depth': [3, 6, 9],\n",
    "    'max_leaf_nodes': [3, 6, 9],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "fdcbfdfd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier(max_depth=6, max_features='sqrt', max_leaf_nodes=9,\n",
      "                       n_estimators=150)\n"
     ]
    }
   ],
   "source": [
    "random_search = RandomizedSearchCV(RandomForestClassifier(),\n",
    "                                   param_grid)\n",
    "random_search.fit(X_train, y_train)\n",
    "print(random_search.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "a7744425",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        high       0.58      0.46      0.51     21941\n",
      "         low       0.61      0.49      0.54     22036\n",
      "      medium       0.17      0.38      0.24      7919\n",
      "\n",
      "    accuracy                           0.46     51896\n",
      "   macro avg       0.46      0.44      0.43     51896\n",
      "weighted avg       0.53      0.46      0.48     51896\n",
      "\n"
     ]
    }
   ],
   "source": [
    "final_model= RandomForestClassifier(max_depth=6, max_features='sqrt', max_leaf_nodes=9,\n",
    "                       n_estimators=150)\n",
    "\n",
    "final_model.fit(X_train, y_train)\n",
    "y_pred_final= final_model.predict(X_test)\n",
    "print(classification_report(y_pred_final, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a0f6c27",
   "metadata": {},
   "source": [
    "Through hyperparameter tuning, we learned that the model can expect target score of 0.86. This score is reasonable, as the model is expected to perform better on training set. However, our current target score is still great. Let's use confusion matrix to further evaluate our model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ab44afb",
   "metadata": {},
   "source": [
    "### Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44238bde",
   "metadata": {},
   "outputs": [],
   "source": [
    "cmat = confusion_matrix(y_test, y_rfc_pred)\n",
    "#print(cmat)\n",
    "print('TP - True Negative {}'.format(cmat[0,0]))\n",
    "print('FP - Flase Positive {}'.format(cmat[0,1]))\n",
    "print('FN - False Negative {}'.format(cmat[1,0]))\n",
    "print('TP - True Positive {}'.format(cmat[1,1]))\n",
    "print('Accuracy Score: {}'.format(np.divide(np.sum([cmat[0,0], cmat[1,1], cmat[2,2]]), np.sum(cmat)))) \n",
    "print('Misclassification Rate: {}'.format(np.divide(np.sum([cmat[1,0], cmat[0,1], cmat[0,2], cmat[2,0], cmat[1,2], cmat[2,1]]), np.sum(cmat))))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "295e7b2b",
   "metadata": {},
   "source": [
    "An accuracy score of 89% is great! We came a long way from our linear regression model. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
